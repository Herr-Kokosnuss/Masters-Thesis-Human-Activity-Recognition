{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import optuna\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from collections import defaultdict, deque\n",
    "from IPython.display import Video\n",
    "from moviepy.editor import *\n",
    "from pytube import YouTube\n",
    "from sklearn.metrics import auc, classification_report, confusion_matrix, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tqdm import tqdm\n",
    "from urllib.request import urlretrieve\n",
    "from yt_dlp import YoutubeDL\n",
    "import yt_dlp as youtube_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define constants\n",
    "SEQUENCE_LENGTH = 30  # Number of frames to use for each video\n",
    "NUM_JOINTS = 33  # Number of joints in MediaPipe Pose\n",
    "#SELECTED_CLASSES = ['Kayaking', 'Basketball', 'JumpRope']\n",
    "SELECTED_CLASSES = ['Kayaking', 'Basketball', 'JumpRope', 'Diving', 'HorseRace', 'PullUps','MilitaryParade']\n",
    "DATASET_DIR = 'workspace/UCF50'\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 30\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract pose from a single frame using MediaPipe\n",
    "def extract_pose(frame):\n",
    "    results = pose.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    if results.pose_landmarks:\n",
    "        landmarks = np.array([[lm.x, lm.y, lm.z] for lm in results.pose_landmarks.landmark])\n",
    "        return landmarks.flatten()\n",
    "    return np.zeros(NUM_JOINTS * 3)\n",
    "\n",
    "# Function to extract pose sequence from a video\n",
    "def extract_pose_sequence(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    skip_frames_window = max(int(frame_count / SEQUENCE_LENGTH), 1)\n",
    "    \n",
    "    poses = []\n",
    "    for _ in range(SEQUENCE_LENGTH):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, _ * skip_frames_window)\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "        pose = extract_pose(frame)\n",
    "        poses.append(pose)\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    # If we don't have enough frames, we'll pad with zeros\n",
    "    while len(poses) < SEQUENCE_LENGTH:\n",
    "        poses.append(np.zeros_like(poses[0]))\n",
    "    \n",
    "    return np.array(poses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess the entire dataset\n",
    "def preprocess_dataset(video_paths, labels):\n",
    "    preprocessed_data = []\n",
    "    preprocessed_labels = []\n",
    "    for video_path, label in tqdm(zip(video_paths, labels), desc=\"Preprocessing dataset\", total=len(video_paths)):\n",
    "        pose_sequence = extract_pose_sequence(video_path)\n",
    "        preprocessed_data.append(pose_sequence)\n",
    "        preprocessed_labels.append(label)\n",
    "    return np.array(preprocessed_data), np.array(preprocessed_labels)\n",
    "\n",
    "# Function to save preprocessed dataset\n",
    "def save_preprocessed_dataset(data, labels, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump((data, labels), f)\n",
    "    print(f\"Preprocessed dataset saved to {filename}\")\n",
    "\n",
    "# Function to load preprocessed dataset\n",
    "def load_preprocessed_dataset(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        data, labels = pickle.load(f)\n",
    "    print(f\"Preprocessed dataset loaded from {filename}\")\n",
    "    return data, labels\n",
    "\n",
    "# Function to load all video paths and labels\n",
    "def load_dataset():\n",
    "    video_paths = []\n",
    "    labels = []\n",
    "    for class_idx, class_name in enumerate(SELECTED_CLASSES):\n",
    "        class_dir = os.path.join(DATASET_DIR, class_name)\n",
    "        for video_name in os.listdir(class_dir):\n",
    "            if video_name.endswith('.avi'):\n",
    "                video_path = os.path.join(class_dir, video_name)\n",
    "                video_paths.append(video_path)\n",
    "                labels.append(class_idx)\n",
    "    return video_paths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess dataset\n",
    "print(\"Loading and preprocessing dataset...\")\n",
    "preprocessed_file = 'preprocessed_pose_dataset_tens-7-32.pkl'\n",
    "\n",
    "if os.path.exists(preprocessed_file):\n",
    "    preprocessed_data, preprocessed_labels = load_preprocessed_dataset(preprocessed_file)\n",
    "else:\n",
    "    video_paths, labels = load_dataset()\n",
    "    preprocessed_data, preprocessed_labels = preprocess_dataset(video_paths, labels)\n",
    "    save_preprocessed_dataset(preprocessed_data, preprocessed_labels, preprocessed_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train and test sets\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    preprocessed_data, preprocessed_labels, test_size=0.2, random_state=42, stratify=preprocessed_labels\n",
    ")\n",
    "\n",
    "# Convert labels to one-hot encoded format\n",
    "train_labels = keras.utils.to_categorical(train_labels)\n",
    "test_labels = keras.utils.to_categorical(test_labels)\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_data, test_labels))\n",
    "\n",
    "# Prepare datasets for training\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(train_data)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def objective(trial):\n",
    "    # Hyperparameters\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n",
    "    lstm_units_1 = trial.suggest_int(\"lstm_units_1\", 64, 256)\n",
    "    lstm_units_2 = trial.suggest_int(\"lstm_units_2\", 64, 256)\n",
    "    dense_units = trial.suggest_int(\"dense_units\", 32, 128)\n",
    "\n",
    "    # Enable mixed precision\n",
    "    policy = mixed_precision.Policy('mixed_float16')\n",
    "    mixed_precision.set_global_policy(policy)\n",
    "\n",
    "    # Model creation\n",
    "    input_shape = (SEQUENCE_LENGTH, NUM_JOINTS * 3)\n",
    "    num_classes = len(SELECTED_CLASSES)\n",
    "    model = create_lstm_model(input_shape, num_classes, lstm_units_1, lstm_units_2, dense_units, dropout_rate)\n",
    "\n",
    "    # Optimizer and loss function\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    optimizer = mixed_precision.LossScaleOptimizer(optimizer)\n",
    "    loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels))\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((test_data, test_labels))\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=len(train_data)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    test_dataset = test_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "    # Training loop\n",
    "    best_val_accuracy = 0\n",
    "    best_epoch = 0\n",
    "    patience = 10  # Early stopping patience\n",
    "    max_epochs = 100  # Maximum number of epochs to try\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        # Train the model\n",
    "        history = model.fit(train_dataset, epochs=1, verbose=0)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        val_loss, val_accuracy = model.evaluate(test_dataset, verbose=0)\n",
    "        \n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_epoch = epoch + 1\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}, Loss: {history.history['loss'][0]:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if epoch + 1 - best_epoch >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    # Report the best epoch as a trial intermediate value\n",
    "    trial.report(best_epoch, step=max_epochs)\n",
    "\n",
    "    return best_val_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Optuna study\n",
    "def run_optuna_study(n_trials=200):\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "    print(\"Number of finished trials: \", len(study.trials))\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "    # Get the best number of epochs\n",
    "    best_epoch = trial.intermediate_values[max(trial.intermediate_values.keys())]\n",
    "    print(f\"  Best number of epochs: {best_epoch}\")\n",
    "\n",
    "    # Add best_epoch to the best parameters\n",
    "    best_params = trial.params\n",
    "    best_params['best_epoch'] = best_epoch\n",
    "\n",
    "    return best_params\n",
    "\n",
    "# Run the Optuna study\n",
    "best_params = run_optuna_study(n_trials=200)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create LSTM model\n",
    "def create_lstm_model(input_shape, num_classes, lstm_units_1, lstm_units_2, dense_units, dropout_rate):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.LSTM(lstm_units_1, return_sequences=True, input_shape=input_shape),\n",
    "        keras.layers.LSTM(lstm_units_2),\n",
    "        keras.layers.Dense(dense_units, activation='relu'),\n",
    "        keras.layers.Dropout(dropout_rate),\n",
    "        keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_final_model(best_params):\n",
    "    # Create the model with best parameters\n",
    "    input_shape = (SEQUENCE_LENGTH, NUM_JOINTS * 3)\n",
    "    num_classes = len(SELECTED_CLASSES)\n",
    "    model = create_lstm_model(input_shape, num_classes, \n",
    "                              best_params['lstm_units_1'], \n",
    "                              best_params['lstm_units_2'], \n",
    "                              best_params['dense_units'], \n",
    "                              best_params['dropout_rate'])\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=best_params['lr'])\n",
    "    optimizer = mixed_precision.LossScaleOptimizer(optimizer)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Prepare datasets\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels))\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((test_data, test_labels))\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=len(train_data)).batch(best_params['batch_size']).prefetch(tf.data.AUTOTUNE)\n",
    "    test_dataset = test_dataset.batch(best_params['batch_size']).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(train_dataset, epochs= 30, validation_data=test_dataset, verbose=1)\n",
    "\n",
    "    # Save the best model\n",
    "    model.save('best_model_optuna.h5')\n",
    "    print(\"Training completed. Best model saved as 'best_model_optuna.h5'\")\n",
    "\n",
    "    return model, history\n",
    "\n",
    "# Train the final model\n",
    "final_model, final_history = train_final_model(best_params)\n",
    "\n",
    "# Print model summary\n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting training curves\n",
    "def plot_training_curves(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(121)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.subplot(122)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_curves.png')\n",
    "    plt.close()\n",
    "    \n",
    "# Plot training curves\n",
    "plot_training_curves(final_history)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "# Prepare test dataset\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_data, test_labels))\n",
    "test_dataset = test_dataset.batch(best_params['batch_size']).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "for frames, labels in tqdm(test_dataset, desc=\"Testing\"):\n",
    "    outputs = final_model.predict(frames)\n",
    "    predicted = np.argmax(outputs, axis=1)\n",
    "    all_predictions.extend(predicted)\n",
    "    all_labels.extend(np.argmax(labels, axis=1))\n",
    "\n",
    "# Calculate and print overall accuracy\n",
    "accuracy = 100 * sum(np.array(all_predictions) == np.array(all_labels)) / len(all_labels)\n",
    "print(f\"Overall Test Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, classes):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm_percent, annot=True, fmt='.1f', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "    plt.title('Confusion Matrix (Percentages)')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig('confusion_matrix_percent.png')\n",
    "    plt.close()\n",
    "\n",
    "plot_confusion_matrix(all_labels, all_predictions, SELECTED_CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot classification report\n",
    "def plot_classification_report(y_true, y_pred, classes):\n",
    "    report = classification_report(y_true, y_pred, target_names=classes, output_dict=True)\n",
    "    df = pd.DataFrame(report).transpose()\n",
    "    df = df.drop(['accuracy', 'macro avg', 'weighted avg'])\n",
    "    df = df.drop('support', axis=1)  # Remove the support column\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax.axis('off')\n",
    "    table = ax.table(cellText=df.values.round(2),\n",
    "                     rowLabels=df.index,\n",
    "                     colLabels=df.columns,\n",
    "                     cellLoc='center',\n",
    "                     loc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1.2, 1.5)\n",
    "\n",
    "    for i, key in enumerate(df.columns):\n",
    "        cell = table[0, i]\n",
    "        cell.set_text_props(weight='bold', color='white')\n",
    "        cell.set_facecolor('#4C72B0')\n",
    "\n",
    "    plt.title('Classification Report', fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('classification_report.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "plot_classification_report(all_labels, all_predictions, SELECTED_CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve\n",
    "def plot_roc_curve(all_labels, all_predictions, SELECTED_CLASSES):\n",
    "    y_true = label_binarize(all_labels, classes=range(len(SELECTED_CLASSES)))\n",
    "    y_pred = label_binarize(all_predictions, classes=range(len(SELECTED_CLASSES)))\n",
    "\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(len(SELECTED_CLASSES)):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true[:, i], y_pred[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    colors = plt.cm.get_cmap('Set1')(np.linspace(0, 1, len(SELECTED_CLASSES)))\n",
    "    for i, color in zip(range(len(SELECTED_CLASSES)), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "                 label=f'ROC curve of {SELECTED_CLASSES[i]} (area = {roc_auc[i]:0.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\", fontsize='small')\n",
    "    plt.savefig('roc_curve.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "plot_roc_curve(all_labels, all_predictions, SELECTED_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to predict and analyze video\n",
    "def predict_and_analyze_video(video_file_path, output_video_path, output_graph_path, final_model, SEQUENCE_LENGTH, SELECTED_CLASSES):\n",
    "    # GPU setup\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(\"Using GPU for predictions\")\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "    else:\n",
    "        print(\"Using CPU for predictions\")\n",
    "\n",
    "    # Initialize MediaPipe Pose\n",
    "    mp_pose = mp.solutions.pose\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "    # Video setup\n",
    "    video_reader = cv2.VideoCapture(video_file_path)\n",
    "    fps = int(video_reader.get(cv2.CAP_PROP_FPS))\n",
    "    frame_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    original_video_width = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    original_video_height = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    video_writer = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'mp4v'), \n",
    "                                   fps, (original_video_width, original_video_height))\n",
    "\n",
    "    # Initialize variables for prediction and analysis\n",
    "    pose_sequence = deque(maxlen=SEQUENCE_LENGTH)\n",
    "    frame_predictions = []\n",
    "    class_probabilities = defaultdict(list)\n",
    "    predicted_class_name = ''\n",
    "\n",
    "    # Process video frames\n",
    "    with tqdm(total=frame_count, desc=\"Processing video\") as pbar:\n",
    "        while video_reader.isOpened():\n",
    "            ok, frame = video_reader.read()\n",
    "            if not ok:\n",
    "                break\n",
    "\n",
    "            # Extract pose from the frame\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = pose.process(frame_rgb)\n",
    "            \n",
    "            if results.pose_landmarks:\n",
    "                landmarks = np.array([[lm.x, lm.y, lm.z] for lm in results.pose_landmarks.landmark])\n",
    "                pose_data = landmarks.flatten()\n",
    "            else:\n",
    "                pose_data = np.zeros(NUM_JOINTS * 3)\n",
    "\n",
    "            pose_sequence.append(pose_data)\n",
    "\n",
    "            if len(pose_sequence) == SEQUENCE_LENGTH:\n",
    "                # Prepare the pose sequence for the model\n",
    "                input_sequence = np.array([list(pose_sequence)])\n",
    "\n",
    "                # Get predictions\n",
    "                outputs = final_model.predict(input_sequence, verbose=0)\n",
    "                probabilities = outputs[0]\n",
    "                predicted_class_index = np.argmax(probabilities)\n",
    "                predicted_class_name = SELECTED_CLASSES[predicted_class_index]\n",
    "\n",
    "                # Store predictions and probabilities\n",
    "                frame_predictions.append(predicted_class_name)\n",
    "                for i, class_name in enumerate(SELECTED_CLASSES):\n",
    "                    class_probabilities[class_name].append(probabilities[i])\n",
    "            else:\n",
    "                frame_predictions.append(None)\n",
    "                for class_name in SELECTED_CLASSES:\n",
    "                    class_probabilities[class_name].append(0)\n",
    "\n",
    "            # Draw the pose on the frame\n",
    "            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "            # Write predicted class name on top of the frame\n",
    "            cv2.putText(frame, predicted_class_name, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "            # Write the frame into the disk using the VideoWriter Object\n",
    "            video_writer.write(frame)\n",
    "\n",
    "            # Update progress bar\n",
    "            pbar.update(1)\n",
    "\n",
    "    video_reader.release()\n",
    "    video_writer.release()\n",
    "\n",
    "    # Pad the beginning of predictions and probabilities\n",
    "    pad_length = SEQUENCE_LENGTH - 1\n",
    "    frame_predictions = [None] * pad_length + frame_predictions[pad_length:]\n",
    "    for class_name in SELECTED_CLASSES:\n",
    "        class_probabilities[class_name] = [0] * pad_length + class_probabilities[class_name][pad_length:]\n",
    "\n",
    "    # Plot frame-by-frame results\n",
    "    plot_frame_by_frame_results(frame_predictions, class_probabilities, fps, output_graph_path)\n",
    "\n",
    "    return frame_predictions, class_probabilities, fps\n",
    "\n",
    "def plot_frame_by_frame_results(frame_predictions, class_probabilities, fps, output_path):\n",
    "    frame_count = len(frame_predictions)\n",
    "    time_axis = np.arange(frame_count) / fps\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Plot class probabilities\n",
    "    plt.subplot(2, 1, 1)\n",
    "    for class_name, probs in class_probabilities.items():\n",
    "        plt.plot(time_axis, probs, label=class_name)\n",
    "    plt.title(\"Class Probabilities Over Time\")\n",
    "    plt.xlabel(\"Time (seconds)\")\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot predicted classes\n",
    "    plt.subplot(2, 1, 2)\n",
    "    unique_classes = list(set(frame_predictions) - {None})\n",
    "    class_to_num = {cls: i for i, cls in enumerate(unique_classes)}\n",
    "    numeric_predictions = [class_to_num[cls] if cls is not None else -1 for cls in frame_predictions]\n",
    "    plt.scatter(time_axis, numeric_predictions, marker='.')\n",
    "    plt.yticks(range(len(unique_classes)), unique_classes)\n",
    "    plt.title(\"Predicted Class Over Time\")\n",
    "    plt.xlabel(\"Time (seconds)\")\n",
    "    plt.ylabel(\"Predicted Class\")\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_video(final_model, SEQUENCE_LENGTH, SELECTED_CLASSES):\n",
    "    test_videos_directory = 'test_videos'\n",
    "    video_title = 'kayaking'  # Replace with the actual video title\n",
    "\n",
    "    input_video_file_path = f'{test_videos_directory}/{video_title}.mp4'\n",
    "    output_video_file_path = f'{test_videos_directory}/{video_title}-Output-SeqLen{SEQUENCE_LENGTH}.mp4'\n",
    "    output_graph_path = f'{test_videos_directory}/{video_title}_frame_analysis.png'\n",
    "\n",
    "    frame_predictions, class_probabilities, fps = predict_and_analyze_video(\n",
    "        input_video_file_path, output_video_file_path, output_graph_path,\n",
    "        final_model, SEQUENCE_LENGTH, SELECTED_CLASSES\n",
    "    )\n",
    "\n",
    "    print(f\"Processed video saved to: {output_video_file_path}\")\n",
    "    print(f\"Frame-by-frame analysis graph saved to: {output_graph_path}\")\n",
    "\n",
    "# Call this function after training your model\n",
    "process_test_video(final_model, SEQUENCE_LENGTH, SELECTED_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extra\n",
    "#Function to download youtube videos\n",
    "def download_yt_videos(yt_url_list, save_dir):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    ydl_opts = {\n",
    "        'outtmpl': os.path.join(save_dir, '%(title)s.%(ext)s'),\n",
    "        'format': 'bestvideo+bestaudio/best',\n",
    "        'merge_output_format': 'mp4'\n",
    "    }\n",
    "    \n",
    "    for url in yt_url_list:\n",
    "        try:\n",
    "            with YoutubeDL(ydl_opts) as ydl:\n",
    "                ydl.download([url])\n",
    "                print(f\"Downloaded: {url}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download {url}: {e}\")\n",
    "\n",
    "yt_url_list = [\n",
    "    'https://www.youtube.com/shorts/5sUhFYATYeM'\n",
    "    \n",
    "]\n",
    "save_dir = 'test_data'\n",
    "download_yt_videos(yt_url_list, save_dir)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
