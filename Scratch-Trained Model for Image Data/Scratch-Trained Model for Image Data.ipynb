{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from collections import defaultdict, deque\n",
    "from IPython.display import Video\n",
    "from moviepy.editor import *\n",
    "from pytube import YouTube\n",
    "from sklearn.metrics import auc, classification_report, confusion_matrix, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tqdm import tqdm\n",
    "from urllib.request import urlretrieve\n",
    "from yt_dlp import YoutubeDL\n",
    "import yt_dlp as youtube_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed \n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define constants\n",
    "SEQUENCE_LENGTH = 15  # Number of frames to use for each video\n",
    "IMG_HEIGHT, IMG_WIDTH = 128, 128  # Image dimensions\n",
    "SELECTED_CLASSES = ['Kayaking', 'Basketball', 'JumpRope']\n",
    "#SELECTED_CLASSES = ['Kayaking', 'Basketball', 'JumpRope', 'Diving', 'HorseRace', 'PullUps','MilitaryParade']\n",
    "\n",
    "DATASET_DIR = 'workspace/UCF50'\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 7\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "# Set device (GPU if available, else CPU)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"Using GPU\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract image sequence from a video\n",
    "def extract_image_sequence(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    skip_frames_window = max(int(frame_count / SEQUENCE_LENGTH), 1)\n",
    "    \n",
    "    images = []\n",
    "    for _ in range(SEQUENCE_LENGTH):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, _ * skip_frames_window)\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "        frame = cv2.resize(frame, (IMG_WIDTH, IMG_HEIGHT))\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        images.append(frame)\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    # If we don't have enough frames, we'll pad with zeros\n",
    "    while len(images) < SEQUENCE_LENGTH:\n",
    "        images.append(np.zeros((IMG_HEIGHT, IMG_WIDTH, 3), dtype=np.uint8))\n",
    "    \n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to save preprocessed dataset\n",
    "def save_preprocessed_dataset(data, labels, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump((data, labels), f)\n",
    "    print(f\"Preprocessed dataset saved to {filename}\")\n",
    "\n",
    "# New function to load preprocessed dataset\n",
    "def load_preprocessed_dataset(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        data, labels = pickle.load(f)\n",
    "    print(f\"Preprocessed dataset loaded from {filename}\")\n",
    "    return data, labels\n",
    "\n",
    "# Function to load all video paths and labels\n",
    "def load_dataset():\n",
    "    video_paths = []\n",
    "    labels = []\n",
    "    for class_idx, class_name in enumerate(SELECTED_CLASSES):\n",
    "        class_dir = os.path.join(DATASET_DIR, class_name)\n",
    "        for video_name in os.listdir(class_dir):\n",
    "            if video_name.endswith('.avi'):\n",
    "                video_path = os.path.join(class_dir, video_name)\n",
    "                video_paths.append(video_path)\n",
    "                labels.append(class_idx)\n",
    "    return video_paths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to apply data augmentation\n",
    "def augment_image_sequence(image_sequence):\n",
    "    augmented_sequence = []\n",
    "    for image in image_sequence:\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "        image = tf.image.random_flip_up_down(image)\n",
    "        image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "        image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
    "        augmented_sequence.append(image)\n",
    "    return tf.stack(augmented_sequence)\n",
    "\n",
    "# Function to preprocess the entire dataset with augmentation\n",
    "def preprocess_dataset(video_paths, labels, augment=False):\n",
    "    preprocessed_data = []\n",
    "    preprocessed_labels = []\n",
    "    for video_path, label in tqdm(zip(video_paths, labels), desc=\"Preprocessing dataset\", total=len(video_paths)):\n",
    "        image_sequence = extract_image_sequence(video_path)\n",
    "        if augment:\n",
    "            image_sequence = augment_image_sequence(image_sequence)\n",
    "        preprocessed_data.append(image_sequence)\n",
    "        preprocessed_labels.append(label)\n",
    "    return np.array(preprocessed_data), np.array(preprocessed_labels)\n",
    "\n",
    "# Load and preprocess dataset\n",
    "print(\"Loading and preprocessing dataset...\")\n",
    "preprocessed_file = 'preprocessed_image_dataset-tens-3.pkl'\n",
    "#preprocessed_file = 'preprocessed_image_dataset-tens-7.pkl'\n",
    "\n",
    "if os.path.exists(preprocessed_file):\n",
    "    preprocessed_data, preprocessed_labels = load_preprocessed_dataset(preprocessed_file)\n",
    "else:\n",
    "    video_paths, labels = load_dataset()\n",
    "    preprocessed_data, preprocessed_labels = preprocess_dataset(video_paths, labels, augment=True)\n",
    "    save_preprocessed_dataset(preprocessed_data, preprocessed_labels, preprocessed_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code to visualize class distribution\n",
    "def visualize_class_distribution(labels, class_names):\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    # Pie chart\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.pie(counts, labels=class_names, autopct='%1.1f%%', startangle=90)\n",
    "    plt.title('Class Distribution in Dataset')\n",
    "    plt.axis('equal')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('class_distribution_pie.png')\n",
    "    plt.close()\n",
    "\n",
    "    print(\"Class distribution visualizations saved as 'class_distribution_bar.png' and 'class_distribution_pie.png'\")\n",
    "\n",
    "# Call the function after preprocessing the dataset\n",
    "visualize_class_distribution(preprocessed_labels, SELECTED_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(preprocessed_labels),\n",
    "    y=preprocessed_labels\n",
    ")\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "print(\"Class weights:\", class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train and test sets\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    preprocessed_data, preprocessed_labels, test_size=0.2, random_state=42, stratify=preprocessed_labels\n",
    ")\n",
    "\n",
    "# Convert labels to one-hot encoded format\n",
    "train_labels = keras.utils.to_categorical(train_labels)\n",
    "test_labels = keras.utils.to_categorical(test_labels)\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_data, test_labels))\n",
    "\n",
    "# Prepare datasets for training\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(train_data)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable mixed precision\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "\n",
    "# Update constants based on given parameters\n",
    "LEARNING_RATE = 0.0003\n",
    "BATCH_SIZE = 16\n",
    "DROPOUT_RATE = 0.32\n",
    "NUM_CONV_LAYERS = 1\n",
    "NUM_FILTERS = 71\n",
    "KERNEL_SIZE = 3\n",
    "LSTM_UNITS = 69\n",
    "\n",
    "# Create CNN-LSTM model\n",
    "def create_cnn_lstm_model(input_shape, num_classes):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # CNN layers\n",
    "    model.add(keras.layers.TimeDistributed(keras.layers.Conv2D(NUM_FILTERS, (KERNEL_SIZE, KERNEL_SIZE), activation='relu', padding='same'), input_shape=input_shape))\n",
    "    model.add(keras.layers.TimeDistributed(keras.layers.BatchNormalization()))\n",
    "    model.add(keras.layers.TimeDistributed(keras.layers.MaxPooling2D((2, 2))))\n",
    "    \n",
    "    for _ in range(NUM_CONV_LAYERS - 1):\n",
    "        model.add(keras.layers.TimeDistributed(keras.layers.Conv2D(NUM_FILTERS, (KERNEL_SIZE, KERNEL_SIZE), activation='relu', padding='same')))\n",
    "        model.add(keras.layers.TimeDistributed(keras.layers.BatchNormalization()))\n",
    "        model.add(keras.layers.TimeDistributed(keras.layers.MaxPooling2D((2, 2))))\n",
    "    \n",
    "    # Flatten the output for the LSTM layers\n",
    "    model.add(keras.layers.TimeDistributed(keras.layers.Flatten()))\n",
    "    \n",
    "    # LSTM layers\n",
    "    model.add(keras.layers.LSTM(LSTM_UNITS, return_sequences=True))\n",
    "    model.add(keras.layers.Dropout(DROPOUT_RATE))\n",
    "    model.add(keras.layers.LSTM(LSTM_UNITS))\n",
    "    model.add(keras.layers.Dropout(DROPOUT_RATE))\n",
    "    \n",
    "    # Dense layers\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(DROPOUT_RATE))\n",
    "    model.add(keras.layers.Dense(num_classes, activation='softmax', dtype='float32'))  # Ensure the output is float32\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "input_shape = (SEQUENCE_LENGTH, IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "num_classes = len(SELECTED_CLASSES)\n",
    "model = create_cnn_lstm_model(input_shape, num_classes)\n",
    "\n",
    "# Compile the model with a mixed precision optimizer\n",
    "optimizer = mixed_precision.LossScaleOptimizer(keras.optimizers.Adam(learning_rate=LEARNING_RATE))\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'],\n",
    "              weighted_metrics=['accuracy'])\n",
    "\n",
    "# Training loop\n",
    "print(\"Starting training...\")\n",
    "best_accuracy = 0\n",
    "train_losses, train_accuracies = [], []\n",
    "val_losses, val_accuracies = [], []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Training\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    for batch in tqdm(train_dataset, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} - Training\"):\n",
    "        metrics = model.train_on_batch(\n",
    "            batch[0], \n",
    "            batch[1], \n",
    "            class_weight=class_weight_dict\n",
    "        )\n",
    "        train_loss += metrics[0]\n",
    "        train_accuracy += metrics[1]  # Assuming accuracy is the second metric\n",
    "    \n",
    "    train_loss /= len(train_dataset)\n",
    "    train_accuracy /= len(train_dataset)\n",
    "    \n",
    "    # Validation\n",
    "    val_loss = 0\n",
    "    val_accuracy = 0\n",
    "    for batch in tqdm(test_dataset, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} - Validation\"):\n",
    "        metrics = model.test_on_batch(\n",
    "            batch[0], \n",
    "            batch[1]\n",
    "        )  # Remove class_weight argument\n",
    "        val_loss += metrics[0]\n",
    "        val_accuracy += metrics[1]  # Assuming accuracy is the second metric\n",
    "    \n",
    "    val_loss /= len(test_dataset)\n",
    "    val_accuracy /= len(test_dataset)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}\")\n",
    "    \n",
    "    if val_accuracy > best_accuracy:\n",
    "        best_accuracy = val_accuracy\n",
    "        model.save('best_model_image.h5')\n",
    "        print(f\"New best model saved with accuracy: {best_accuracy:.2f}\")\n",
    "\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation curves\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(121)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.subplot(122)\n",
    "plt.plot(train_accuracies, label='Train Accuracy')\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_curves.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training, evaluate the model on the test set\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "for frames, labels in tqdm(test_dataset, desc=\"Testing\"):\n",
    "    outputs = model.predict(frames)\n",
    "    predicted = np.argmax(outputs, axis=1)\n",
    "    all_predictions.extend(predicted)\n",
    "    all_labels.extend(np.argmax(labels, axis=1))\n",
    "\n",
    "# Calculate and print overall accuracy\n",
    "accuracy = 100 * sum(np.array(all_predictions) == np.array(all_labels)) / len(all_labels)\n",
    "print(f\"Overall Test Accuracy: {accuracy:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, classes):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm_percentage, annot=True, fmt='.2f', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "    plt.title('Confusion Matrix (Percentage)')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.close()\n",
    "\n",
    "plot_confusion_matrix(all_labels, all_predictions, SELECTED_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the classification report\n",
    "report = classification_report(all_labels, all_predictions, target_names=SELECTED_CLASSES, output_dict=True)\n",
    "\n",
    "# Convert the report to a DataFrame and remove unwanted rows\n",
    "df = pd.DataFrame(report).transpose()\n",
    "df = df.drop(['accuracy', 'macro avg', 'weighted avg'])\n",
    "df = df.drop('support', axis=1)  # Remove the support column\n",
    "\n",
    "# Create a figure and axis for the table\n",
    "fig, ax = plt.subplots(figsize=(12, 8))  # Increased figure size\n",
    "\n",
    "# Hide axes\n",
    "ax.axis('off')\n",
    "\n",
    "# Create the table\n",
    "table = ax.table(cellText=df.values.round(2),\n",
    "                 rowLabels=df.index,\n",
    "                 colLabels=df.columns,\n",
    "                 cellLoc='center',\n",
    "                 loc='center')\n",
    "\n",
    "# Modify table properties\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(9)  # Slightly smaller font to fit more classes\n",
    "table.scale(1.2, 1.5)\n",
    "\n",
    "# Color the header row\n",
    "for i, key in enumerate(df.columns):\n",
    "    cell = table[0, i]\n",
    "    cell.set_text_props(weight='bold', color='white')\n",
    "    cell.set_facecolor('#4C72B0')\n",
    "\n",
    "# Set title\n",
    "plt.title('Classification Report', fontsize=16, fontweight='bold', pad=20)\n",
    "\n",
    "# Save the figure\n",
    "plt.tight_layout()\n",
    "plt.savefig('classification_report.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "y_true = label_binarize(all_labels, classes=range(len(SELECTED_CLASSES)))\n",
    "y_pred = label_binarize(all_predictions, classes=range(len(SELECTED_CLASSES)))\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(len(SELECTED_CLASSES)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true[:, i], y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(12, 8))  # Increased figure size\n",
    "colors = plt.cm.get_cmap('Set1')(np.linspace(0, 1, len(SELECTED_CLASSES)))\n",
    "for i, color in zip(range(len(SELECTED_CLASSES)), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label=f'ROC curve of {SELECTED_CLASSES[i]} (area = {roc_auc[i]:0.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\", fontsize='small')  # Smaller font size for legend\n",
    "plt.savefig('roc_curve.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict on video and generate frame-by-frame analysis\n",
    "def predict_and_analyze_video(video_file_path, output_video_path, output_graph_path, model, SEQUENCE_LENGTH, SELECTED_CLASSES):\n",
    "    # GPU setup\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    if len(physical_devices) > 0:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "        print(\"GPU is available and will be used for predictions.\")\n",
    "    else:\n",
    "        print(\"No GPU found. Using CPU for predictions.\")\n",
    "    \n",
    "    # Suppress TensorFlow logging\n",
    "    tf.get_logger().setLevel('ERROR')\n",
    "    \n",
    "    # Video setup\n",
    "    video_reader = cv2.VideoCapture(video_file_path)\n",
    "    fps = int(video_reader.get(cv2.CAP_PROP_FPS))\n",
    "    frame_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    original_video_width = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    original_video_height = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    video_writer = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'mp4v'), \n",
    "                                   fps, (original_video_width, original_video_height))\n",
    "\n",
    "    # Initialize variables for prediction and analysis\n",
    "    frame_queue = deque(maxlen=SEQUENCE_LENGTH)\n",
    "    frame_predictions = []\n",
    "    class_probabilities = defaultdict(list)\n",
    "    predicted_class_name = ''\n",
    "\n",
    "    # Process video frames\n",
    "    with tqdm(total=frame_count, desc=\"Processing video\") as pbar:\n",
    "        while video_reader.isOpened():\n",
    "            ok, frame = video_reader.read()\n",
    "            if not ok:\n",
    "                break\n",
    "\n",
    "            # Preprocess the frame\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame_resized = cv2.resize(frame_rgb, (IMG_WIDTH, IMG_HEIGHT))\n",
    "            frame_queue.append(frame_resized)\n",
    "\n",
    "            if len(frame_queue) == SEQUENCE_LENGTH:\n",
    "                # Prepare the frame sequence for the model\n",
    "                input_frames = np.array([frame_queue])\n",
    "\n",
    "                # Get predictions\n",
    "                with tf.device('/GPU:0'):\n",
    "                    outputs = model.predict(input_frames, verbose=0)\n",
    "                probabilities = outputs[0]\n",
    "                predicted_class_index = np.argmax(probabilities)\n",
    "                predicted_class_name = SELECTED_CLASSES[predicted_class_index]\n",
    "\n",
    "                # Store predictions and probabilities\n",
    "                frame_predictions.append(predicted_class_name)\n",
    "                for i, class_name in enumerate(SELECTED_CLASSES):\n",
    "                    class_probabilities[class_name].append(probabilities[i])\n",
    "            else:\n",
    "                frame_predictions.append(None)\n",
    "                for class_name in SELECTED_CLASSES:\n",
    "                    class_probabilities[class_name].append(0)\n",
    "\n",
    "            # Write predicted class name on top of the frame\n",
    "            cv2.putText(frame, predicted_class_name, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "            # Write the frame into the disk using the VideoWriter Object\n",
    "            video_writer.write(frame)\n",
    "\n",
    "            # Update progress bar\n",
    "            pbar.update(1)\n",
    "\n",
    "    video_reader.release()\n",
    "    video_writer.release()\n",
    "\n",
    "    # Pad the beginning of predictions and probabilities\n",
    "    pad_length = SEQUENCE_LENGTH - 1\n",
    "    frame_predictions = [None] * pad_length + frame_predictions[pad_length:]\n",
    "    for class_name in SELECTED_CLASSES:\n",
    "        class_probabilities[class_name] = [0] * pad_length + class_probabilities[class_name][pad_length:]\n",
    "\n",
    "    # Plot frame-by-frame results\n",
    "    plot_frame_by_frame_results(frame_predictions, class_probabilities, fps, output_graph_path)\n",
    "\n",
    "    return frame_predictions, class_probabilities, fps\n",
    "def plot_frame_by_frame_results(frame_predictions, class_probabilities, fps, output_path):\n",
    "    frame_count = len(frame_predictions)\n",
    "    time_axis = np.arange(frame_count) / fps\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Plot class probabilities\n",
    "    plt.subplot(2, 1, 1)\n",
    "    for class_name, probs in class_probabilities.items():\n",
    "        plt.plot(time_axis, probs, label=class_name)\n",
    "    plt.title(\"Class Probabilities Over Time\")\n",
    "    plt.xlabel(\"Time (seconds)\")\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot predicted classes\n",
    "    plt.subplot(2, 1, 2)\n",
    "    unique_classes = list(set(frame_predictions) - {None})\n",
    "    class_to_num = {cls: i for i, cls in enumerate(unique_classes)}\n",
    "    numeric_predictions = [class_to_num[cls] if cls is not None else -1 for cls in frame_predictions]\n",
    "    plt.scatter(time_axis, numeric_predictions, marker='.')\n",
    "    plt.yticks(range(len(unique_classes)), unique_classes)\n",
    "    plt.title(\"Predicted Class Over Time\")\n",
    "    plt.xlabel(\"Time (seconds)\")\n",
    "    plt.ylabel(\"Predicted Class\")\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "def process_test_video(model, SEQUENCE_LENGTH, SELECTED_CLASSES):\n",
    "    test_videos_directory = 'test_videos'\n",
    "    video_title = 'basketball'  # Replace with the actual video title\n",
    "\n",
    "    input_video_file_path = f'{test_videos_directory}/{video_title}.mp4'\n",
    "    output_video_file_path = f'{test_videos_directory}/{video_title}-Output-SeqLen{SEQUENCE_LENGTH}.mp4'\n",
    "    output_graph_path = f'{test_videos_directory}/{video_title}_frame_analysis.png'\n",
    "\n",
    "    frame_predictions, class_probabilities, fps = predict_and_analyze_video(\n",
    "        input_video_file_path, output_video_file_path, output_graph_path,\n",
    "        model, SEQUENCE_LENGTH, SELECTED_CLASSES\n",
    "    )\n",
    "\n",
    "    print(f\"Processed video saved to: {output_video_file_path}\")\n",
    "    print(f\"Frame-by-frame analysis graph saved to: {output_graph_path}\")\n",
    "\n",
    "# Call this function after training your model\n",
    "process_test_video(model, SEQUENCE_LENGTH, SELECTED_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXTRA\n",
    "#Function to download youtube videos\n",
    "def download_yt_videos(yt_url_list, save_dir):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    ydl_opts = {\n",
    "        'outtmpl': os.path.join(save_dir, '%(title)s.%(ext)s'),\n",
    "        'format': 'bestvideo+bestaudio/best',\n",
    "        'merge_output_format': 'mp4'\n",
    "    }\n",
    "    \n",
    "    for url in yt_url_list:\n",
    "        try:\n",
    "            with YoutubeDL(ydl_opts) as ydl:\n",
    "                ydl.download([url])\n",
    "                print(f\"Downloaded: {url}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download {url}: {e}\")\n",
    "\n",
    "yt_url_list = [\n",
    "    'https://www.youtube.com/shorts/7fj2-7o2XAg'\n",
    "    \n",
    "]\n",
    "save_dir = 'test_data'\n",
    "download_yt_videos(yt_url_list, save_dir)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
